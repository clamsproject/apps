{
  "name": "Whisper Wrapper",
  "description": "A CLAMS wrapper for Whisper-based ASR software originally developed by OpenAI.",
  "app_version": "v15",
  "mmif_version": "1.1.0",
  "analyzer_version": "20250625",
  "app_license": "Apache 2.0",
  "analyzer_license": "MIT",
  "identifier": "http://apps.clams.ai/whisper-wrapper/v15",
  "url": "https://github.com/clamsproject/app-whisper-wrapper",
  "input": [
    [
      {
        "@type": "http://mmif.clams.ai/vocabulary/AudioDocument/v1",
        "required": true
      },
      {
        "@type": "http://mmif.clams.ai/vocabulary/VideoDocument/v1",
        "required": true
      }
    ]
  ],
  "output": [
    {
      "@type": "http://mmif.clams.ai/vocabulary/TextDocument/v1"
    },
    {
      "@type": "http://mmif.clams.ai/vocabulary/TimeFrame/v6",
      "properties": {
        "timeUnit": "milliseconds"
      }
    },
    {
      "@type": "http://mmif.clams.ai/vocabulary/Alignment/v1"
    },
    {
      "@type": "http://vocab.lappsgrid.org/Token"
    },
    {
      "@type": "http://vocab.lappsgrid.org/Sentence"
    }
  ],
  "parameters": [
    {
      "name": "model",
      "description": "(from openai-whisper CLI) name of the Whisper model to use",
      "type": "string",
      "default": "turbo",
      "multivalued": false
    },
    {
      "name": "language",
      "description": "(from openai-whisper CLI) language spoken in the audio, specify None to perform language detection",
      "type": "string",
      "default": "",
      "multivalued": false
    },
    {
      "name": "task",
      "description": "(from openai-whisper CLI) whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
      "type": "string",
      "choices": [
        "transcribe",
        "translate"
      ],
      "default": "transcribe",
      "multivalued": false
    },
    {
      "name": "initialPrompt",
      "description": "(from openai-whisper CLI) optional text to provide as a prompt for the first window.",
      "type": "string",
      "default": "",
      "multivalued": false
    },
    {
      "name": "conditionOnPreviousText",
      "description": "(from openai-whisper CLI) if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop",
      "type": "string",
      "default": true,
      "multivalued": false
    },
    {
      "name": "noSpeechThreshold",
      "description": "(from openai-whisper CLI) if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
      "type": "number",
      "default": 0.6,
      "multivalued": false
    },
    {
      "name": "pretty",
      "description": "The JSON body of the HTTP response will be re-formatted with 2-space indentation",
      "type": "boolean",
      "default": false,
      "multivalued": false
    },
    {
      "name": "runningTime",
      "description": "The running time of the app will be recorded in the view metadata",
      "type": "boolean",
      "default": false,
      "multivalued": false
    },
    {
      "name": "hwFetch",
      "description": "The hardware information (architecture, GPU and vRAM) will be recorded in the view metadata",
      "type": "boolean",
      "default": false,
      "multivalued": false
    }
  ]
}