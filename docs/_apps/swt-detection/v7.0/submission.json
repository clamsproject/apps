{
  "time": "2024-11-04T22:00:05+00:00",
  "submitter": "keighrim",
  "image": "ghcr.io/clamsproject/app-swt-detection:v7.0",
  "releasenotes": "This version re-implements stitcher based on `simple-timepoints-stitcher`\n\n- app now can run stitch-only mode (`useClassifier` and `useStitcher`)\n    - simple-timepoints-stitcher app will retire\n- prefixed all parameters with their corresponding modes (e.g., `sampleRat\ne` > `tpSampleRate`, `minTPScore` > `tfMinTPScore`\n- changes to parameters\n    - `minTFCount` (frame count-based) became `tfMinTFDuration` (time-based)\n    - `map` became `tfLabelMap` to clarify what \"map\" the param sets\n    - `tfDynamicSceneLabels` is added to configure dynamic scene types that need multiple representative images/timepoints (defaults to [`credit`, ` credits`])\n    - default values for stitcher parameters are changed based on recent experiments. Most significantly now `minTPScore` defaults to 0.5 and `minTFScore` defaults to 0.9. See https://github.com/clamsproject/aapb-evaluations/issues/60 to read the full experimental reports.\n- changes to app behavior\n    - new stitcher implementation is not exactly the same as the old, and users should expect more \"break-ups\" in the middle of long time frames\n    - for dynamic scene types, the gap between representative time points is now twice the `tfMinTFDuration` value\n    - image classification is now done in batches (currently fixed to size 2000) to reduce memory usage. This will add some time overhead to image extraction process\n\n"
}
